{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pushk\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (4,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400277, 2) (400277, 7) (50064, 2) (50064, 7)\n"
     ]
    }
   ],
   "source": [
    "path='../../Data/Extracted/'\n",
    "\n",
    "############\n",
    "### Here load condensed text data if required ###\n",
    "### Get the code for that from the last cell ###\n",
    "#############\n",
    "\n",
    "train_text=pd.read_csv(path+'train_multi_column_text.csv')\n",
    "test_text=pd.read_csv(path+'test_multi_column_text.csv')\n",
    "\n",
    "train_num=pd.read_csv(path+'train.csv').select_dtypes(exclude='object')\n",
    "train_num.fillna(train_num.median(),inplace=True)\n",
    "\n",
    "test_num=pd.read_csv(path+'test.csv').select_dtypes(exclude='object')\n",
    "test_num.fillna(test_num.median(),inplace=True)\n",
    "\n",
    "############\n",
    "### Here load binned numeric data if required ###\n",
    "### Get the code for that from the last cell ###\n",
    "#############\n",
    "\n",
    "labels=pd.read_csv(path+'labels.csv')\n",
    "labels=pd.get_dummies(labels,prefix_sep='__')\n",
    "\n",
    "print(train_num.shape, train_text.shape, test_num.shape, test_text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scaling numeric data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=preprocessing.MinMaxScaler()\n",
    "train_num=scaler.fit_transform(train_num)\n",
    "test_num=scaler.transform(test_num)\n",
    "\n",
    "############\n",
    "### Here tfidf vectorize single column text vector if required ###\n",
    "### Get the code for that from the last cell ###\n",
    "############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vectorize train and test text by TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14432405893c4d4daf167106d351353a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_csr=[train_num]\n",
    "test_csr=[test_num]\n",
    "\n",
    "############\n",
    "### Here tfidf vectorize single column text vector if required ###\n",
    "### Get the code for that from the last cell ###\n",
    "############\n",
    "\n",
    "\n",
    "for feat in tqdm(train_text.columns):\n",
    "    vectorizer=TfidfVectorizer(ngram_range=(1,4),min_df=10)\n",
    "    train_csr.append(vectorizer.fit_transform(train_text[feat].values.ravel()))\n",
    "    test_csr.append(vectorizer.transform(test_text[feat].values.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ECC (Ensemble Classifier Chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b300a6432b4b27ad00a39c37dffbca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import utils, linear_model, model_selection, metrics\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import os\n",
    "\n",
    "###### Clean files from the previous session #####\n",
    "#shutil.rmtree('./best_model')\n",
    "\n",
    "########### Data Sets ###############\n",
    "# Sparse data set ready for model\n",
    "X_train=scipy.sparse.hstack(train_csr).tocsr()\n",
    "X_test=scipy.sparse.hstack(test_csr).tocsr()\n",
    "\n",
    "############ iterator ##################\n",
    "#https://www.kaggle.com/c/instacart-market-basket-analysis/discussion/37753#\n",
    "def iter_minibatches(chunksize, X,y):\n",
    "    # Provide chunks one by one\n",
    "    chunk_start_marker = 0\n",
    "    while chunk_start_marker < X.shape[0]:\n",
    "        chunkrows = range(chunk_start_marker, min(chunk_start_marker + chunksize,X.shape[0]))\n",
    "        # you need to implement \"getrows\" (based on what your data source is - RAM/Disc/...)\n",
    "        X_chunk, y_chunk = X[chunkrows],y[chunkrows]\n",
    "        yield X_chunk, y_chunk # get next portion of data to train on\n",
    "        chunk_start_marker += chunksize # update starting point\n",
    "\n",
    "\n",
    "########################### ECC Implementation ###########################\n",
    "\n",
    "columns=np.array(labels.columns)\n",
    "for cc_num in tqdm(range(40,100)):\n",
    "    \n",
    "    # Random subset of data set\n",
    "    X_train_sample,labels_train_sample=utils.resample(X_train,labels,n_samples=int(np.floor((X_train.shape[0])*0.2)),random_state=cc_num)\n",
    "\n",
    "\n",
    "    # random sequence of columns\n",
    "    np.random.shuffle(columns)\n",
    "    \n",
    "    # Create new copy of X_train, X_test, and labels for new chain\n",
    "    X_te=X_test.copy()\n",
    "    #X_train_copy=X_train.copy()\n",
    "    #labels_tr=labels.copy()\n",
    "    \n",
    "    for ind,label in enumerate(columns):\n",
    "        \n",
    "        min_samples=2\n",
    "        for i in labels_train_sample[label].unique():\n",
    "            min_samples=min(labels_train_sample[label][labels_train_sample[label]==i].shape[0], min_samples)\n",
    "        \n",
    "        if min_samples>1:\n",
    "            # Split with stratify\n",
    "            X_tr,X_cv,y_tr,y_cv=model_selection.train_test_split(X_train_sample,labels_train_sample[label].values,stratify=labels_train_sample[label],test_size=0.2,random_state=44)\n",
    "        else:\n",
    "            # Split without stratify\n",
    "            X_tr,X_cv,y_tr,y_cv=model_selection.train_test_split(X_train_sample,labels_train_sample[label].values,test_size=0.2,random_state=44)\n",
    "        \n",
    "        ############\n",
    "        ### Here do feature selection and transformation if required ###\n",
    "        ### Get the code for that from the last cell ###\n",
    "        ############\n",
    "        \n",
    "        # Path to store best model while training and early stopping\n",
    "        path='./best_model/'+str(cc_num)+'/'+label\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        # model to be train\n",
    "        clf=linear_model.SGDClassifier(loss='log',\n",
    "                                     eta0=0.001,\n",
    "                                     validation_fraction=0.2,\n",
    "                                     early_stopping=False,\n",
    "                                     n_jobs=-1) # Estimator\n",
    "\n",
    "        improvement=[10e10] # Track cv score while fitting the model\n",
    "        epoch=0\n",
    "        cnt=0\n",
    "        patience=10 # Number of epochs to wait without improvement in cv loss\n",
    "        max_epochs=1000\n",
    "        tol=0.001\n",
    "\n",
    "        # Train while we hit our patience level and trigger early stopping or we reach max epoch number\n",
    "        while cnt<patience and epoch<max_epochs:\n",
    "\n",
    "            # Use batcheterator for mini-batch SGD\n",
    "            batcheterator=iter_minibatches(10000,X_tr,y_tr)\n",
    "            min_loss=np.min(improvement) # Note min_loss for each epoch\n",
    "            for x_chunk,y_chunk in batcheterator:\n",
    "                # Note: classes argument must get number of classes from the entire data set\n",
    "                clf.partial_fit(x_chunk,y_chunk,classes=np.unique(labels[label]))\n",
    "            improvement.append(metrics.log_loss(y_cv,clf.predict_proba(X_cv),labels=np.unique(labels[label])))\n",
    "            curr_loss=improvement[-1]\n",
    "\n",
    "            if (min_loss-curr_loss)>tol:\n",
    "                # If current loss is less than the current minimum loss then this is our best model so far\n",
    "                #best_train_prediction=clf.predict(X_tr)\n",
    "                #best_cv_prediction=clf.predict(X_cv)\n",
    "                best_test_prediction=np.array(list(map(lambda val:val[1],clf.predict_proba(X_te))))\n",
    "                \n",
    "                np.save(path+'/best_prediction.npy',best_test_prediction)\n",
    "                \n",
    "                cnt=0\n",
    "            else:\n",
    "                # Model did not improve\n",
    "                cnt+=1\n",
    "\n",
    "            epoch+=1\n",
    "        \n",
    "        ########## Augment X_train_sample, and X_te #############\n",
    "        best_train_prediction=clf.predict(X_train_sample)\n",
    "        X_train_sample=scipy.sparse.hstack([X_train_sample,best_train_prediction.reshape(-1,1)]).tocsr()\n",
    "        \n",
    "        X_te=scipy.sparse.hstack([X_te,best_test_prediction.reshape(-1,1)]).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create final submission data frame and save it as csv file into Submissions folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b137ec7546394487abe10eb5d3a02dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=104.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create submission data frame according to appropriate submission format\n",
    "path='../../Data/'\n",
    "submission_format=pd.read_csv(path+'Original/SubmissionFormat.csv')\n",
    "\n",
    "sub_columns=submission_format.columns[1:]\n",
    "sub_index=submission_format[submission_format.columns[0]].values\n",
    "\n",
    "del submission_format\n",
    "gc.collect()\n",
    "\n",
    "# Create final submssions dictionary\n",
    "path='best_model/'\n",
    "#final_preds={}\n",
    "final_label_pred=[]\n",
    "for label in tqdm(sub_columns):\n",
    "    cc_preds=[]\n",
    "    for cc_num in os.listdir(path):\n",
    "        cc_preds.append(np.load(path+cc_num+'/'+label+'/best_prediction.npy'))\n",
    "    preds_stack=np.vstack(cc_preds).T\n",
    "    \n",
    "    quartiles=np.quantile(preds_stack,[0.25,0.75],axis=1).T\n",
    "    \n",
    "    label_preds=[]\n",
    "    for ind,arr in enumerate(preds_stack):\n",
    "        label_preds.append(np.mean(arr[(arr>=quartiles[ind][0]) & (arr<=quartiles[ind][1])]))\n",
    "        \n",
    "    final_label_pred.append(label_preds)\n",
    "\n",
    "# Create submission data frame\n",
    "sub_df=pd.DataFrame(dict(zip(sub_columns,final_label_pred)),index=sub_index)\n",
    "\n",
    "# Save submission file into submissions folder\n",
    "path='../../Data/'\n",
    "sub_df.to_csv(path+'Submissions/ECC_8.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function__Aides Compensation</th>\n",
       "      <th>Function__Career &amp; Academic Counseling</th>\n",
       "      <th>Function__Communications</th>\n",
       "      <th>Function__Curriculum Development</th>\n",
       "      <th>Function__Data Processing &amp; Information Services</th>\n",
       "      <th>Function__Development &amp; Fundraising</th>\n",
       "      <th>Function__Enrichment</th>\n",
       "      <th>Function__Extended Time &amp; Tutoring</th>\n",
       "      <th>Function__Facilities &amp; Maintenance</th>\n",
       "      <th>Function__Facilities Planning</th>\n",
       "      <th>...</th>\n",
       "      <th>Student_Type__Special Education</th>\n",
       "      <th>Student_Type__Unspecified</th>\n",
       "      <th>Use__Business Services</th>\n",
       "      <th>Use__ISPD</th>\n",
       "      <th>Use__Instruction</th>\n",
       "      <th>Use__Leadership</th>\n",
       "      <th>Use__NO_LABEL</th>\n",
       "      <th>Use__O&amp;M</th>\n",
       "      <th>Use__Pupil Services &amp; Enrichment</th>\n",
       "      <th>Use__Untracked Budget Set-Aside</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180042</th>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.023443</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.862879</td>\n",
       "      <td>0.004507</td>\n",
       "      <td>0.006751</td>\n",
       "      <td>0.795404</td>\n",
       "      <td>0.003975</td>\n",
       "      <td>0.068580</td>\n",
       "      <td>0.024490</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.007438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28872</th>\n",
       "      <td>0.004690</td>\n",
       "      <td>0.016844</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.010011</td>\n",
       "      <td>0.019245</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.068332</td>\n",
       "      <td>0.040127</td>\n",
       "      <td>0.026494</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014906</td>\n",
       "      <td>0.916989</td>\n",
       "      <td>0.013810</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.130022</td>\n",
       "      <td>0.076273</td>\n",
       "      <td>0.034470</td>\n",
       "      <td>0.033688</td>\n",
       "      <td>0.143141</td>\n",
       "      <td>0.002421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186915</th>\n",
       "      <td>0.083634</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>0.009422</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>0.011389</td>\n",
       "      <td>0.009045</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029813</td>\n",
       "      <td>0.327082</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>0.801747</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.038330</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.010519</td>\n",
       "      <td>0.005808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412396</th>\n",
       "      <td>0.083421</td>\n",
       "      <td>0.005866</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.011412</td>\n",
       "      <td>0.009034</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029903</td>\n",
       "      <td>0.323090</td>\n",
       "      <td>0.003106</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.804030</td>\n",
       "      <td>0.011644</td>\n",
       "      <td>0.038078</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.010519</td>\n",
       "      <td>0.005803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427740</th>\n",
       "      <td>0.003114</td>\n",
       "      <td>0.028040</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>0.010973</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.012281</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.013272</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>0.980733</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.023888</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>0.799655</td>\n",
       "      <td>0.013729</td>\n",
       "      <td>0.013196</td>\n",
       "      <td>0.017389</td>\n",
       "      <td>0.002190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169063</th>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.011008</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.006718</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.019586</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.018747</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>0.213402</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>0.637095</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>0.000309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433255</th>\n",
       "      <td>0.026733</td>\n",
       "      <td>0.011008</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.006718</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.019586</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.018747</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>0.213393</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>0.637098</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>0.000309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232204</th>\n",
       "      <td>0.026765</td>\n",
       "      <td>0.011007</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.019581</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.213620</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>0.636663</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.006514</td>\n",
       "      <td>0.000309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171685</th>\n",
       "      <td>0.026733</td>\n",
       "      <td>0.011008</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.006718</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.019586</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.018747</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>0.213391</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>0.637099</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>0.000309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249087</th>\n",
       "      <td>0.026732</td>\n",
       "      <td>0.011007</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.006718</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.019586</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.018747</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>0.213385</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>0.637104</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>0.000309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50064 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Function__Aides Compensation  Function__Career & Academic Counseling  \\\n",
       "180042                      0.008811                                0.002826   \n",
       "28872                       0.004690                                0.016844   \n",
       "186915                      0.083634                                0.005885   \n",
       "412396                      0.083421                                0.005866   \n",
       "427740                      0.003114                                0.028040   \n",
       "...                              ...                                     ...   \n",
       "169063                      0.026735                                0.011008   \n",
       "433255                      0.026733                                0.011008   \n",
       "232204                      0.026765                                0.011007   \n",
       "171685                      0.026733                                0.011008   \n",
       "249087                      0.026732                                0.011007   \n",
       "\n",
       "        Function__Communications  Function__Curriculum Development  \\\n",
       "180042                  0.000515                          0.001319   \n",
       "28872                   0.001919                          0.010011   \n",
       "186915                  0.001524                          0.006020   \n",
       "412396                  0.001526                          0.006008   \n",
       "427740                  0.002619                          0.003487   \n",
       "...                          ...                               ...   \n",
       "169063                  0.000292                          0.000718   \n",
       "433255                  0.000292                          0.000718   \n",
       "232204                  0.000292                          0.000717   \n",
       "171685                  0.000292                          0.000718   \n",
       "249087                  0.000292                          0.000718   \n",
       "\n",
       "        Function__Data Processing & Information Services  \\\n",
       "180042                                          0.006074   \n",
       "28872                                           0.019245   \n",
       "186915                                          0.009422   \n",
       "412396                                          0.009400   \n",
       "427740                                          0.010973   \n",
       "...                                                  ...   \n",
       "169063                                          0.006718   \n",
       "433255                                          0.006718   \n",
       "232204                                          0.006715   \n",
       "171685                                          0.006718   \n",
       "249087                                          0.006718   \n",
       "\n",
       "        Function__Development & Fundraising  Function__Enrichment  \\\n",
       "180042                             0.000504              0.003750   \n",
       "28872                              0.001010              0.068332   \n",
       "186915                             0.001311              0.003506   \n",
       "412396                             0.001312              0.003494   \n",
       "427740                             0.001274              0.012281   \n",
       "...                                     ...                   ...   \n",
       "169063                             0.000290              0.001667   \n",
       "433255                             0.000290              0.001667   \n",
       "232204                             0.000290              0.001663   \n",
       "171685                             0.000290              0.001667   \n",
       "249087                             0.000290              0.001667   \n",
       "\n",
       "        Function__Extended Time & Tutoring  \\\n",
       "180042                            0.002233   \n",
       "28872                             0.040127   \n",
       "186915                            0.011389   \n",
       "412396                            0.011412   \n",
       "427740                            0.002069   \n",
       "...                                    ...   \n",
       "169063                            0.001057   \n",
       "433255                            0.001057   \n",
       "232204                            0.001055   \n",
       "171685                            0.001057   \n",
       "249087                            0.001057   \n",
       "\n",
       "        Function__Facilities & Maintenance  Function__Facilities Planning  \\\n",
       "180042                            0.023443                       0.000672   \n",
       "28872                             0.026494                       0.001691   \n",
       "186915                            0.009045                       0.002225   \n",
       "412396                            0.009034                       0.002226   \n",
       "427740                            0.013272                       0.001721   \n",
       "...                                    ...                            ...   \n",
       "169063                            0.019586                       0.000254   \n",
       "433255                            0.019586                       0.000254   \n",
       "232204                            0.019581                       0.000254   \n",
       "171685                            0.019586                       0.000254   \n",
       "249087                            0.019586                       0.000254   \n",
       "\n",
       "        ...  Student_Type__Special Education  Student_Type__Unspecified  \\\n",
       "180042  ...                         0.004920                   0.862879   \n",
       "28872   ...                         0.014906                   0.916989   \n",
       "186915  ...                         0.029813                   0.327082   \n",
       "412396  ...                         0.029903                   0.323090   \n",
       "427740  ...                         0.007967                   0.980733   \n",
       "...     ...                              ...                        ...   \n",
       "169063  ...                         0.001768                   0.018747   \n",
       "433255  ...                         0.001768                   0.018747   \n",
       "232204  ...                         0.001766                   0.018800   \n",
       "171685  ...                         0.001768                   0.018747   \n",
       "249087  ...                         0.001768                   0.018747   \n",
       "\n",
       "        Use__Business Services  Use__ISPD  Use__Instruction  Use__Leadership  \\\n",
       "180042                0.004507   0.006751          0.795404         0.003975   \n",
       "28872                 0.013810   0.040100          0.130022         0.076273   \n",
       "186915                0.003111   0.016972          0.801747         0.011667   \n",
       "412396                0.003106   0.016949          0.804030         0.011644   \n",
       "427740                0.023548   0.023888          0.008006         0.799655   \n",
       "...                        ...        ...               ...              ...   \n",
       "169063                0.001215   0.003050          0.213402         0.006920   \n",
       "433255                0.001215   0.003050          0.213393         0.006920   \n",
       "232204                0.001215   0.003049          0.213620         0.006923   \n",
       "171685                0.001215   0.003050          0.213391         0.006920   \n",
       "249087                0.001215   0.003050          0.213385         0.006920   \n",
       "\n",
       "        Use__NO_LABEL  Use__O&M  Use__Pupil Services & Enrichment  \\\n",
       "180042       0.068580  0.024490                          0.003900   \n",
       "28872        0.034470  0.033688                          0.143141   \n",
       "186915       0.038330  0.002983                          0.010519   \n",
       "412396       0.038078  0.002968                          0.010519   \n",
       "427740       0.013729  0.013196                          0.017389   \n",
       "...               ...       ...                               ...   \n",
       "169063       0.637095  0.000783                          0.006519   \n",
       "433255       0.637098  0.000783                          0.006519   \n",
       "232204       0.636663  0.000784                          0.006514   \n",
       "171685       0.637099  0.000783                          0.006519   \n",
       "249087       0.637104  0.000783                          0.006519   \n",
       "\n",
       "        Use__Untracked Budget Set-Aside  \n",
       "180042                         0.007438  \n",
       "28872                          0.002421  \n",
       "186915                         0.005808  \n",
       "412396                         0.005803  \n",
       "427740                         0.002190  \n",
       "...                                 ...  \n",
       "169063                         0.000309  \n",
       "433255                         0.000309  \n",
       "232204                         0.000309  \n",
       "171685                         0.000309  \n",
       "249087                         0.000309  \n",
       "\n",
       "[50064 rows x 104 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1) Feature scaling normalize and standardize\n",
    "\n",
    "    # Nomalize train and test data sets\n",
    "    train_num=preprocessing.normalize(train_num)\n",
    "    test_num=preprocessing.normalize(test_num)\n",
    "\n",
    "    # scale and shift the data set with standard scaler\n",
    "    std=preprocessing.StandardScaler()\n",
    "    train_num=std.fit_transform(train_num)\n",
    "    test_num=std.transform(test_num)\n",
    "\n",
    "2) Use this code for train and cv data set split for each chain\n",
    "\n",
    "    # Random subset of data set\n",
    "    X_tr_sample,y_tr_sample=utils.resample(X_train,labels,n_samples=int(np.floor((X_train.shape[0])*0.4)),random_state=cc_num)\n",
    "    \n",
    "    # train test split to evaluate model performance on cv data set to decide early stopping\n",
    "    train_ind,cv_ind=model_selection.train_test_split(range(X_tr_sample.shape[0]),test_size=0.2,random_state=44)\n",
    "    \n",
    "    # Create train and cv sets\n",
    "    X_tr,y_tr_df=X_tr_sample[train_ind,:],y_tr_sample.iloc[train_ind]\n",
    "    X_cv,y_cv_df=X_tr_sample[cv_ind,:],y_tr_sample.iloc[cv_ind]\n",
    "    \n",
    "3) Feature selection\n",
    "\n",
    "    # Select 5000 features for current classifier\n",
    "    feat_select=SelectKBest(score_func=chi2,k=5000)\n",
    "\n",
    "    # transform train, cv, te set only for this classifier\n",
    "    X_tr=feat_select.fit_transform(X_tr,y_tr)\n",
    "    X_cv=feat_select.transform(X_cv)\n",
    "    X_te_temp=feat_select.transform(X_te)\n",
    "\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
