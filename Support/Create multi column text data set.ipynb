{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import nltk\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read train and test files from extraced folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pushk\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (4,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "path='../../Data/Extracted/'\n",
    "train=pd.read_csv(path+'train.csv').select_dtypes(include='object')\n",
    "test=pd.read_csv(path+'test.csv').select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train['Facility_or_Department'], train['Text_2'], train['Text_3'], train['Text_4'], train['Text_1'], train['SubFund_Description'], train['Position_Extra']\n",
    "del test['Facility_or_Department'], test['Text_2'], test['Text_3'], test['Text_4'], test['Text_1'], test['SubFund_Description'], test['Position_Extra']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean the text <br>\n",
    "## 2.1 Fill na by string 'empty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna('empty',inplace=True)\n",
    "test.fillna('empty',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Define function for text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontraction(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "def preprocess(feat_list):\n",
    "    for ind,row in enumerate(feat_list):\n",
    "        # Replace everything except a-z, A-Z and 0-9 by empty string\n",
    "        row=re.sub(pattern='[^a-zA-Z0-9]+',repl=' ',string=row).strip()\n",
    "        row=decontraction(row)\n",
    "        feat_list[ind]=row\n",
    "    return feat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Execute preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455e8d10499a4216a0b5a30ea13413df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c2d1c6c9e64ec2b253d3a62b674418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for feat in tqdm(train.columns):\n",
    "    train[feat]=preprocess(train[feat].str.lower().values)\n",
    "for feat in tqdm(test.columns):\n",
    "    test[feat]=preprocess(test[feat].str.lower().values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(los):\n",
    "    '''Takes a list of strings aka 'los' and removes the stop words from each of the strings'''\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    \n",
    "    # Set of stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return list(map(lambda doc: ' '.join(list(filter(lambda word: word not in stop_words, word_tokenize(doc)))), los))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in train.columns:\n",
    "    train[feat]=remove_stopwords(train[feat].values)\n",
    "for feat in test.columns:\n",
    "    test[feat]=remove_stopwords(test[feat].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in train.columns:\n",
    "    for row in range(train.shape[0]):\n",
    "        if not len(train[feat].iloc[row])>0:\n",
    "            train[feat].iloc[row]='empty'\n",
    "            \n",
    "for feat in test.columns:\n",
    "    for row in range(test.shape[0]):\n",
    "        if not len(test[feat].iloc[row])>0:\n",
    "            test[feat].iloc[row]='empty'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Save data frames to extracted folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../../Data/Extracted/'\n",
    "\n",
    "train.to_csv(path+'train_multi_column_text.csv',index=False)\n",
    "test.to_csv(path+'test_multi_column_text.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
